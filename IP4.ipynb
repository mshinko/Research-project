{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOr4FMMwvSgD6uFKHNwwu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshinko/Research-project/blob/main/IP4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzH0WEzLf6kw",
        "outputId": "0de78fd9-b040-498f-bbb9-e0a1a0e035e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D78Wbz601HW",
        "outputId": "66998045-b236-4b3d-aa27-57fd76b48c72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.1.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o75hbrvO05vA",
        "outputId": "b715afb1-7785-430d-aa78-797854f400dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrHKZeA5PdMs",
        "outputId": "9d873725-ecb5-4b5a-cfb0-6df089460abc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irBUzkZXzoAO",
        "outputId": "bd2356ef-45d8-45e3-8ee0-afbe790354bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input = 512\n",
        "max_target = 128\n",
        "batch_size = 3\n",
        "model_checkpoints = \"facebook/bart-large-xsum\""
      ],
      "metadata": {
        "id": "0s-rarqH0y75"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Use triple-quoted strings to preserve the formatting\n",
        "original_text = \"\"\"\n",
        "  To: VRSS Management Team\n",
        "    From: David Schlingloff\n",
        "    Subject: VRSS Management Report – Week ending January 30th, 2022\n",
        "    Copies: Management Team, Advisors\n",
        "\n",
        "    Priorities\n",
        "    We are working on these priorities:\n",
        "    1. Finalize a set of interested and motivated team members.\n",
        "    2. Define competitors to the VRSS product.\n",
        "    3. Identify possible methods of VR streaming.\n",
        "\n",
        "    Progress\n",
        "    During this (short) reporting period, we accomplished these tasks:\n",
        "    - Developed the idea and company:\n",
        "      - Brainstormed possible ideas to pursue and decided upon the VR service.\n",
        "      - Created a name for the company (Virtual Reality Sports Seating - VRSS).\n",
        "    - Founded the Team:\n",
        "      - Confirmed 4 teammates (we may accept more in the following days).\n",
        "      - Drafted our MOKRs for discussion.\n",
        "\n",
        "    Plans\n",
        "    During the next week, we plan to finish these tasks:\n",
        "    - Find 5 competitors to the planned VRSS service:\n",
        "      - Perform research online to develop 5 possible competitors (both direct and indirect) to VRSS service by Friday, February 4th (Alex, Ryan, Matt).\n",
        "    - Brainstorm 4 VR streaming-capable cameras:\n",
        "      - Find 4 different types of video cameras (preferably inexpensive, <$1000) that can support VR streaming capabilities by Friday, February 4th.\n",
        "      - Begin understanding the limitations of streaming bandwidth (David, Kartik).\n",
        "\n",
        "    Problems\n",
        "    We are aware of these problems:\n",
        "    - We need to finalize our team:\n",
        "      - There are still people who were interested in joining last week but left too early to make a final decision. We would like to complete this by the end of class on Monday, January 31st.\n",
        "    - We are unsure if cameras can support our bandwidth:\n",
        "      - The team would like to use a limited number of cameras that can be accessed by many different people during a game. The team is unsure if it is even possible to get these types of cameras without spending excessive amounts of money.\n",
        "    - We do not currently have experience with software/website creation:\n",
        "      - Much of the VRSS streaming service is dependent on a reliable stream with easy website access. A lot of our resources will need to be spent on attempting to create an appealing website with streaming capabilities.\n",
        "\n",
        "    Management Report.doc 2022Jan30 Page 1/2\n",
        "\n",
        "    Attachments\n",
        "    - None.\n",
        "\"\"\"\n",
        "\n",
        "# Define the summary\n",
        "summary = \"Week 1 Created the team and MOKR. Plan to find competitors and understand technology needed. They lack the knowledge to build a streaming service solution and it is unclear who their customers are that would pay for it. Identified problems but don’t have plans for mitigating.\"\n",
        "\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Original Text': [original_text], 'Summary': [summary]})\n",
        "# Define the new row data as a dictionary\n",
        "new_row = {\n",
        "    'Original Text': \"\"\"\n",
        "    To: VRSS Management Team\n",
        "    From: David Schlingloff\n",
        "    Subject: VRSS Management Report – Week ending February 6th, 2022\n",
        "    Copies: Management Team, Advisors\n",
        "\n",
        "    Priorities\n",
        "    We are working on these priorities:\n",
        "    1. Finalize a set of interested and motivated team members.\n",
        "    2. Defining competitors to the VRSS product.\n",
        "    3. Identifying possible methods of VR streaming.\n",
        "\n",
        "    Progress\n",
        "    During this (short) reporting period, we accomplished these tasks:\n",
        "    - Find 5 competitors to the planned VRSS service – Developed 5 possible\n",
        "    competitors (both direct and indirect) to VRSS service.\n",
        "    - Brainstorm 4 VR streaming capable cameras - Found 4+ different types of\n",
        "    video cameras (preferably inexpensive, <$1000) that can support VR\n",
        "    streaming capabilities.\n",
        "\n",
        "    Plans\n",
        "    During the next week, we plan to finish these tasks:\n",
        "    - Refine our target consumers - Talk about refining the consumers we defined\n",
        "    last week. Build upon this by creating 3 theoretical customer profiles (David,\n",
        "    Alex, Matthew).\n",
        "    - Define our advisory board - We will think about the people that would be\n",
        "    helpful for us to talk to. Think about areas we could ask questions in. Using\n",
        "    these topics, search for people we can possibly talk to and discuss our project\n",
        "    plan. (Ryan, Entire Team).\n",
        "    - Find specific details about 3 competitors - From the competitors we found\n",
        "    last week, go on their websites and explore what they do and learn about\n",
        "    their history. Specifically, create a document by February 11th, with the\n",
        "    following 3 things noted for each: similarities/differences between company\n",
        "    and VRSS, the prices for that service, and if/how they advertise. (Kartik,\n",
        "    Ryan).\n",
        "\n",
        "    Problems\n",
        "    We are aware of these problems:\n",
        "    - We do not currently have experience with software / website creation –\n",
        "    Much of the VRSS streaming service is dependent on a reliable stream\n",
        "    with easy website access. A lot of our resources will need to be spent on\n",
        "    attempting to create an appealing website with streaming capabilities.\n",
        "    - Defining our place in the market is tricky - The team mapped out the\n",
        "    two existing markets - going to sports games and streaming them on TV.\n",
        "    We realized that there is a definitive space in the market for VR streaming,\n",
        "    but it might be tricky to convince the target consumers to pursue this\n",
        "    option versus the others.\n",
        "    - Finding VR capable equipment is expensive - VR is still a relatively new\n",
        "    type of streaming, and therefore the market for this technology is still\n",
        "    relatively niche. Finding equipment (like a VR capable camera) is possible,\n",
        "    but our requirement of <$1000 makes it difficult.\n",
        "    - Our marketing efforts/strategy is a current problem we have. In order to\n",
        "    acquire a lot of customers and produce sales, our marketing and\n",
        "    advertising will need to be phenomenal. We could develop a social media\n",
        "    account (Instagram/Facebook) and/or pay for a commercial\n",
        "    advertisement on TV.\n",
        "\n",
        "    Management Report.doc 2022Feb06 Page 1/5\n",
        "\n",
        "    Attachments\n",
        "    - None.\n",
        "    \"\"\",\n",
        "    'Summary': \"\"\"\n",
        "    Week 2\n",
        "    Found competitors and VR streaming cameras. Plan on analyzing competition, find advisory board members, and create 3 customer profiles. They lack the knowledge to build a streaming service solution, the equipment is too expensive and it is unclear who their customers are that would pay for it. Identified problems but don’t have plans for mitigating.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "# Append the new row to the DataFrame\n",
        "df = df.append(new_row, ignore_index=True)\n",
        "# Define the new row\n",
        "new_row_2 = {\n",
        "    'Original Text': \"\"\"\n",
        "   To: VRSS Management Team\n",
        "From: David Schlingloff\n",
        "Subject: VRSS Management Report – Week ending February 13th, 2022\n",
        "Copies: Management Team, Advisors\n",
        "Priorities\n",
        "We are working on these priorities:\n",
        "1. Gauge the interest of VR equipment with our target markets\n",
        "2. Identify a way to live-stream in VR\n",
        "3. Brainstorm ways to begin website creation\n",
        "Progress\n",
        "During this reporting period, we accomplished these tasks:\n",
        "● Refined our target consumers - Developed our ideal target market by\n",
        "creating 3 theoretical customer profiles based on the 3 customer groups that\n",
        "the team developed.\n",
        "● Defined our advisory board - Listed nine people that the team would like to\n",
        "invite to the first project review meeting. Each person has different unique\n",
        "talents and abilities that could help the team move forward.\n",
        "● Scheduled VR equipment rental - Reserved a VR camera and VR headset at\n",
        "the Virginia Tech library so that the team can begin testing with the\n",
        "equipment.\n",
        "● Find specific details about 3 competitors - Unable to accomplish this in the\n",
        "week timeframe. The team decided that the information we already have is\n",
        "enough to move forward with and we spent our resources on other tasks.\n",
        "Plans\n",
        "During the next week, we plan to finish these tasks:\n",
        "● Create an interest survey - Use google forms to develop a survey that can\n",
        "gauge the interest in this service based on the 3 target markets defined by\n",
        "February 17th. Generate a list of 9 people (three from each target market) to\n",
        "be sent out by February 21st. (Kartik, Ryan, Alex)\n",
        "● Obtain and use VR equipment - Receive the VR camera and headset from\n",
        "the Virginia Tech library and attempt to connect to the computer. See if it is\n",
        "possible to first record a video in VR. Then work on streaming options if time\n",
        "permits for the week. The team will research and document the process for\n",
        "video recording and video streaming (if possible). (David, all team)\n",
        "\n",
        "Management Report.doc 2022Feb13 Page 1/3\n",
        "\n",
        "Problems\n",
        "We are aware of these problems:\n",
        "● We still do not currently have experience with software / website\n",
        "creation – Much of the VRSS streaming service is dependent on a reliable\n",
        "stream with easy website access. A lot of our resources will need to be\n",
        "spent on attempting to create an appealing website with streaming\n",
        "capabilities. However, we are now looking at meeting with people who do\n",
        "have this experience and developing a plan of integration.\n",
        "● VR equipment implementation requires resources - Although the team\n",
        "was successful in figuring out a way to rent VR equipment, it has realized\n",
        "that in order to record and stream video, a powerful and expensive\n",
        "computer is needed. It will need to be portable so that it can be moved to\n",
        "where the VR cameras are located.\n",
        "● Our marketing efforts/strategy - In order to acquire a lot of customers and\n",
        "produce sales, our marketing and advertising will need to be phenomenal.\n",
        "We could develop a social media account (instagram/facebook) and/or\n",
        "pay for\n",
        "    \"\"\",\n",
        "    'Summary': \"\"\"\n",
        "    Week 3\n",
        "    Created customer profiles, list of potential advisory board members, and reserved VR equipment rentals to address the expense constraint identified last week. Failed to analyze competitors they believe they have sufficient information to move forward though not clear what that is. They plan to create an interest survey (as opposed to interviewing as indicated in MOKR) and record a VR video with rented equipment. They lack the knowledge to build a streaming service solution, the equipment is too expensive. They continue to have the same problems but don’t have plans for mitigating. Will need to intervene to get them unstuck.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "\n",
        "# Append the new row to the DataFrame\n",
        "df = df.append(new_row_2, ignore_index=True)\n",
        "new_row3 = {\n",
        "    'Original Text': \"\"\"\n",
        "    To: VRSS Management Team\n",
        "From: David Schlingloff\n",
        "Subject: VRSS Management Report – Week ending March 4th, 2022\n",
        "Copies: Management Team, Advisors\n",
        "Priorities\n",
        "We are working on these priorities:\n",
        "1. Get people to take our survey and evaluate the results.\n",
        "2. Identify a way to live-stream in VR\n",
        "3. Submit a video to KickstartVT\n",
        "Progress\n",
        "During this reporting period, we accomplished these tasks:\n",
        "● Analyzed interest survey results - Received 25 responses from the survey and\n",
        "wrote a one-page report summarizing the key-findings from the survey that was\n",
        "sent out. The team found that we should continue to pursue this product. (Matt,\n",
        "Ryan, Alex)\n",
        "● Obtained and use VR equipment - Obtained the Oculus Go and successfully\n",
        "connected it to YouTube VR. The process was documented and an Oculus Quest\n",
        "2 was scheduled for rent to attempt to do the same thing. If it works as well, then\n",
        "we will discuss using the Insta360 camera to live-stream to the Oculus Quest 2.\n",
        "(David, Kartik)\n",
        "● Performed individual project reviews - Gave the presentation to our advisory\n",
        "board members. (David, all team members)\n",
        "\n",
        "Plans\n",
        "During the next week, we plan to finish these tasks:\n",
        "● Finalize interest survey results - Synthesize the survey results and add to our\n",
        "report and project review presentation. (Ryan, Matt, Alex)\n",
        "● Obtain and use VR equipment - Obtain the Oculus Quest 2 and see if it can\n",
        "connect to YouTube VR. If so, document the process and start to discuss\n",
        "live-streaming options using the Insta360 camera. (Alex, Kartik)\n",
        "● Perform team project review - Revise presentation template for the class and\n",
        "present the project review to the team on Wednesday, March 16th. Record the\n",
        "comments from the Q&A. (David, all team members)\n",
        "● Create a video for KickStartVT - Record and edit a video for KickstartVT and\n",
        "submit on Sunday, March 20th. (David, all team members)\n",
        "\n",
        "Problems\n",
        "We are aware of these problems:\n",
        "● We can only rent equipment for a limited period - We would like to rent an\n",
        "Oculus Go or an Oculus Quest (since they are stand-alone devices), but they\n",
        "require rentals so timing can get delayed significantly.\n",
        "● We still do not currently have experience with software / website creation –\n",
        "Much of the VRSS streaming service is dependent on a reliable stream with easy\n",
        "website access. A lot of our resources will need to be spent on attempting to\n",
        "create an appealing website with streaming capabilities. However, we are now\n",
        "looking at meeting with people who do have this experience and developing a\n",
        "plan of integration.\n",
        "● Our marketing efforts/strategy - In order to acquire a lot of customers and\n",
        "produce sales, our marketing and advertising will need to be aggressive. We\n",
        "could develop a social media account (instagram/facebook) and/or pay for a\n",
        "commercial advertisement on TV.\n",
        "    \"\"\",\n",
        "    'Summary': \"\"\"\n",
        "  Week 5\n",
        "Sent out the previously created interest survey and tried out an HTC Vive but didn’t  function with Youtube App. Scheduled time with advisory board and potential team member. Plan to try an Oculus Go, analyze the survey data, and prepare for the project review. They still lack the knowledge to build a streaming service solution, the renting of the vr equipment is too burdensome  due to rental policies. They continue to have the same problems of website creation and marketing  but don’t have plans for mitigating. Will need to intervene to get them unstuck.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "}\n",
        "df = df.append(new_row3, ignore_index=True)\n",
        "# Print the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP-M9ZQ90zB8",
        "outputId": "26128771-5728-4f3c-d12c-9850ad6923f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       Original Text  \\\n",
            "0  \\n  To: VRSS Management Team\\n    From: David ...   \n",
            "1  \\n    To: VRSS Management Team\\n    From: Davi...   \n",
            "2  \\n   To: VRSS Management Team\\nFrom: David Sch...   \n",
            "3  \\n    To: VRSS Management Team\\nFrom: David Sc...   \n",
            "\n",
            "                                             Summary  \n",
            "0  Week 1 Created the team and MOKR. Plan to find...  \n",
            "1  \\n    Week 2\\n    Found competitors and VR str...  \n",
            "2  \\n    Week 3\\n    Created customer profiles, l...  \n",
            "3  \\n  Week 5\\nSent out the previously created in...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-1b301e5e3f85>:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(new_row, ignore_index=True)\n",
            "<ipython-input-8-1b301e5e3f85>:194: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(new_row_2, ignore_index=True)\n",
            "<ipython-input-8-1b301e5e3f85>:256: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(new_row3, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Your DataFrame df contains the data\n",
        "\n",
        "# Split the data into training (70%), testing (15%), and validation (15%) sets\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "test_df, val_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Now you"
      ],
      "metadata": {
        "id": "7xRCRupq00D3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-xsum\")\n",
        "# Assuming you have already tokenized your testing and validation data\n",
        "tokenized_inputs_test = tokenizer(test_df['Original Text'].tolist(), truncation=True, padding='max_length', max_length=max_input, return_tensors=\"pt\", add_special_tokens=True)\n",
        "tokenized_targets_test = tokenizer(test_df['Summary'].tolist(), truncation=True, padding='max_length', max_length=max_target, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "tokenized_inputs_val = tokenizer(val_df['Original Text'].tolist(), truncation=True, padding='max_length', max_length=max_input, return_tensors=\"pt\", add_special_tokens=True)\n",
        "tokenized_targets_val = tokenizer(val_df['Summary'].tolist(), truncation=True, padding='max_length', max_length=max_target, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "# Now, you can create data loaders for testing and validation\n",
        "test_dataset = CustomDataset(tokenized_inputs_test, tokenized_targets_test)\n",
        "val_dataset = CustomDataset(tokenized_inputs_val, tokenized_targets_val)\n",
        "\n",
        "# Create data loaders\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "uHVc4Q401fav"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenized_inputs, tokenized_targets):\n",
        "        self.input_ids = tokenized_inputs['input_ids']\n",
        "        self.attention_mask = tokenized_inputs['attention_mask']\n",
        "        self.labels = tokenized_targets['input_ids']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create instances of your custom dataset for training, testing, and validation\n",
        "train_dataset = CustomDataset(tokenized_inputs, tokenized_targets)\n",
        "test_dataset = CustomDataset(tokenized_inputs_test, tokenized_targets_test)\n",
        "val_dataset = CustomDataset(tokenized_inputs_val, tokenized_targets_val)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 3  # You can adjust this based on your hardware limitations\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GSkhyX-11ffp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    evaluation_strategy=\"steps\",  # \"steps\" or \"epoch\"\n",
        "    save_total_limit=1,  # Number of checkpoints to keep\n",
        "    save_steps=100,  # Save a checkpoint every X steps\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    learning_rate=1e-4,  # Learning rate\n",
        "    output_dir=\"./model_checkpoint\",  # Directory to save the model\n",
        "    save_strategy=\"steps\",  # \"steps\" or \"epoch\"\n",
        "    eval_steps=100,  # Evaluate every X steps\n",
        "    logging_steps=100,  # Log every X steps\n",
        "    push_to_hub=False,  # Set to True to push model checkpoints to the Hugging Face Hub\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "laojod5S1fi4",
        "outputId": "42207c58-5c3e-4242-d5f1-5f78dfdeaa67"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5f7cec631247>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeq2SeqTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m training_args = Seq2SeqTrainingArguments(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mevaluation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# \"steps\" or \"epoch\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args_seq2seq.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_xla_device_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \"\"\"\n\u001b[1;32m   1851\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.20.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1768\u001b[0m                     \u001b[0;34m\"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 )\n",
            "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFGjouce1flg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ylmwtEaG1fn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}